<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Phuong Nam Tran</title> <meta name="author" content="Phuong Nam Tran"> <meta name="description" content="An Artificial Intelligence Researcher. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%96%A5%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://namphuongtran9196.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Websites</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Phuong Nam</span> Tran </h1> <p class="desc"><a href="https://uni.fpt.edu.vn/en-US/home" rel="external nofollow noopener" target="_blank">FPTU University, Ho Chi Minh Campus</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?3b5fe401043b371e34deab9354694115" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>+84 946 653 380</p> <p>AI Researcher</p> </div> </div> <div class="clearfix"> <p><strong>Short Bio:</strong> My name is Tran <strong>Phuong Nam</strong> (Tr·∫ßn <strong>Ph∆∞∆°ng Nam</strong> - Vietnamese). I received a B.Eng degree in Artificial Intelligence from <a href="https://uni.fpt.edu.vn/en-US/home" rel="external nofollow noopener" target="_blank">FPT University</a>, Vietnam, in 2023.</p> <p>From 2021 to 2023, I was a Junior AI Engineer at <a href="http://www.kng.vn/" rel="external nofollow noopener" target="_blank">K&amp;G company</a>, in Vietnam. During this time, I also worked as an AI researcher at startup <a href="https://www.linkedin.com/company/pythera-ai/about/" rel="external nofollow noopener" target="_blank">Pythera AI</a> which took account into many projects related to Natural Language Processing and Computer Vision.Currently, I work as an AI researcher under the guidance of Dr. <a href="https://dnmduc.github.io/" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a>. at FPT University, Ho Chi Minh City, Vietnam.</p> <p><strong>Research Interests:</strong> Artificial Intelligence, Deep Learning, Machine Learning, Signal Processing, Multi-Modal, Reinforcement learning, and their applications in the fields of Biometrics, Audio &amp; Speech Processing, Self-Driving Car, Intelligent automation, and Robotics.</p> </div> <h2><a href="/news/" style="color: inherit;">üì∞Newsüì∞</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Feb 25, 2024</th> <td> <a class="news-title" href="/news/announcement_2024_02_25/">üóûÔ∏è 03 papers are presented at 9th International Conference on Intelligent Information Technology (ICIIT 2024), Feb 24 -25, 2024.</a> </td> </tr> <tr> <th scope="row">Feb 20, 2024</th> <td> <a class="news-title" href="/news/announcement_2024_02_20/">üóûÔ∏è 01 papers are presented at EAI INISCOM 2024 - 10th EAI International Conference on Industrial Networks and Intelligent Systems, Feb 20-21, 2024.</a> </td> </tr> <tr> <th scope="row">Jan 19, 2024</th> <td> <a class="news-title" href="/news/announcement_2024_01_19/">üóûÔ∏è 01 papers is presented at The ICOIN 2024 - The 38th International Conference on Information Networking</a> </td> </tr> <tr> <th scope="row">Dec 29, 2023</th> <td> <a class="news-title" href="/news/announcement_2023_12_29/">01 papers is accepted at The EAI INISCOM 2024 - 10th EAI International Conference on Industrial Networks and Intelligent Systems</a> </td> </tr> <tr> <th scope="row">Dec 23, 2023</th> <td> <a class="news-title" href="/news/announcement_2023_12_23/">01 papers are accepted at The 38th International Conference on Information Networking (ICOIN 2024)</a> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">üìëSelected publicationsüìë</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/conference/ictc/ComSER_icon-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/conference/ictc/ComSER_icon-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/conference/ictc/ComSER_icon-1400.webp"></source> <img src="/assets/img/publication_preview/conference/ictc/ComSER_icon.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="publication_preview/conference/ictc/ComSER_icon.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="IEEE:conf/ICTC/ComSER" class="col-sm-8"> <div class="title">Comparative analysis of multi-loss functions for enhanced multi-modal speech emotion recognition</div> <div class="author"> <em>Phuong-Nam Tran</em>,¬†<a href="https://scholar.google.at/citations?user=gD7_QBQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Thuy-Duong Thi Vu</a>,¬†<a href="https://nhattruongpham.github.io/" rel="external nofollow noopener" target="_blank">Nhat Truong Pham</a>,¬†<a href="https://scholar.google.com/citations?user=RuwRj8EAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Hanh Dang-Ngoc</a>,¬†and¬†<a href="https://scholar.google.com/citations?user=2UKP440AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a> </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/10392928" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/namphuongtran9196/3m-ser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ICTC58733.2023.10392928" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In recent years, multi-modal analysis has gained significant prominence across domains such as audio/speech processing, natural language processing, and affective computing, with a particular focus on speech emotion recognition (SER). The integration of data from diverse sources, encompassing text, audio, and images, in conjunction with classifier algorithms has led to the realization of enhanced performance in SER tasks. Traditionally, the cross-entropy loss function has been employed for the classification problem. However, it is challenging to discriminate the feature representations among classes for multi-modal classification tasks. In this study, we focus on the impact of the loss functions on multi-modal SER rather than designing the model architecture. Mainly, we evaluate the performance of multi-modal SER with different loss functions, such as cross-entropy loss, center loss, contrastive-center loss, and their combinations. Based on extensive comparative analysis, it is proven that the combination of cross-entropy loss and contrastive-center loss achieves the best performance for multi-modal SER. This combination reaches the highest accuracy of 80.27% and the highest balanced accuracy of 81.44% on the IEMOCAP dataset.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/conference/ictc/Vitexco_icon-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/conference/ictc/Vitexco_icon-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/conference/ictc/Vitexco_icon-1400.webp"></source> <img src="/assets/img/publication_preview/conference/ictc/Vitexco_icon.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="publication_preview/conference/ictc/Vitexco_icon.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="IEEE:conf/ICTC/Vitexco" class="col-sm-8"> <div class="title">Vitexco: Exemplar-based Video Colorization using Vision Transformer</div> <div class="author"> <a href="https://scholar.google.com/citations?user=kz_chQ4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Duong Thanh Tran</a>,¬†<em>Phuong-Nam Tran</em>,¬†<a href="https://scholar.google.com/citations?user=-aEoZCgAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Doan Hieu Nguyen Nguyen</a>,¬†<a href="https://scholar.google.at/citations?user=gD7_QBQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Thuy-Duong Thi Vu</a>,¬†Trung Thanh Pham,¬†and¬†<a href="https://scholar.google.com/citations?user=2UKP440AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a> </div> <div class="periodical"> <em>In 2023 14th International Conference on Information and Communication Technology Convergence (ICTC)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/10393505" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ICTC58733.2023.10393505" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In the field of image and video colorization, the existing research employs a CNN to extract information from each video frame. However, due to the local nature of a kernel, it is challenging for CNN to capture the relationships between each pixel and others in an image, leading to inaccurate colorization. To solve this issue, we introduce an end-to-end network called Vitexco for colorizing videos. Vitexco utilizes the power of the Vision Transformer (ViT) to capture the relationships among all pixels in a frame with each other, providing a more effective method for colorizing video frames. We evaluate our approach on DAVIS datasets and demonstrate that it outperforms the state-of-the-art methods regarding color accuracy and visual quality. Our findings suggest that using a ViT can significantly enhance the performance of video colorization.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%61%6D%70%68%75%6F%6E%67%74%72%61%6E%39%31%39%36@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0009-0009-6551-9106" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=NKbwDD8AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Phuong-Nam-Tran/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://www.scopus.com/authid/detail.uri?authorId=57185035100" title="Scopus" rel="external nofollow noopener" target="_blank"><i class="ai ai-scopus"></i></a> <a href="https://github.com/namphuongtran9196" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/namphuongtran9196" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/namtp9196" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> <a href="https://gitlab.com/namphuongtran9196" title="GitLab" rel="external nofollow noopener" target="_blank"><i class="fab fa-gitlab"></i></a> <a href="https://www.kaggle.com/tpnnam" title="Kaggle" rel="external nofollow noopener" target="_blank"><i class="fab fa-kaggle"></i></a> <a href="https://instagram.com/namphuongtran9196" title="Instagram" rel="external nofollow noopener" target="_blank"><i class="fab fa-instagram"></i></a> <a href="https://facebook.com/namphuongtran9196" title="Facebook" rel="external nofollow noopener" target="_blank"><i class="fab fa-facebook"></i></a> <a href="https://discord.com/users/840177865592537100" title="Discord" rel="external nofollow noopener" target="_blank"><i class="fab fa-discord"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> </div> </div> <div style="width: 150px; margin: 0 auto"> <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=xW7nMfAHDma4ZgSElvdBVQL-ntbmeGrv_H6wyuEbSpM&amp;cl=ffffff&amp;w=a"></script> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2024 Phuong Nam Tran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: June 03, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>