<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Phuong Nam Tran</title> <meta name="author" content="Phuong Nam Tran"> <meta name="description" content="An Artificial Intelligence Researcher. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%96%A5%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://namphuongtran9196.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Websites</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Phuong Nam</span> Tran </h1> <p class="desc"><a href="https://uni.fpt.edu.vn/en-US/home" rel="external nofollow noopener" target="_blank">FPTU University, Ho Chi Minh Campus</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?810aee926e2025617f466a36f48d0972" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>+84 946 653 380</p> <p>Postgraduate Researcher</p> </div> </div> <div class="clearfix"> <p><strong>Short Bio:</strong> My name is Tran Phuong <strong>Nam</strong> (Trần Phương <strong>Nam</strong> - Vietnamese). I received a B.Eng degree in Artificial Intelligence from <a href="https://uni.fpt.edu.vn/en-US/home" rel="external nofollow noopener" target="_blank">FPT University</a>, Vietnam, in 2023. My research interests include Deep Learning, Computer Vision, Natural Language Processing, Multi-modal, Reinforcement learning, and the Internet of Things.</p> <p>From 2021 to 2023, I was a Junior AI Engineer with <a href="http://www.kng.vn/" rel="external nofollow noopener" target="_blank">K&amp;G company</a>, in Vietnam. During this time, I also worked as an AI researcher at startup <a href="https://www.linkedin.com/company/gradtek/about/" rel="external nofollow noopener" target="_blank">Gradients Technologies</a> which took account into many projects related to Natural Language Processing and Computer Vision.Currently, I work as an AI researcher under the guidance of Dr. <a href="https://dnmduc.github.io/" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a>. at FPT University, Ho Chi Minh City, Vietnam.</p> <p><strong>Research Interests:</strong> Artificial Intelligence, Deep Learning, Machine Learning, Signal Processing, Multi-Modal, Reinforcement learning, and their applications in the fields of Biometrics, Audio &amp; Speech Processing, Self-Driving Car, Intelligent automation, and Robotics.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Nov 20, 2023</th> <td> <a class="news-title" href="/news/announcement_2023_11_20/">02 papers are accepted at The 2024 9th International Conference on Intelligent Information Technology (ICIIT 2024)</a> </td> </tr> <tr> <th scope="row">Nov 12, 2023</th> <td> <a class="news-title" href="/news/announcement_3/">Awarded valedictorian of information technology at FPT University Graduation Ceremony</a> </td> </tr> <tr> <th scope="row">Aug 26, 2023</th> <td> <a class="news-title" href="/news/announcement_1/">03 papers are accepted at The 14th International Conference on ICT Convergence, Jeju, Korea, Oct 11 -13, 2023.</a> </td> </tr> <tr> <th scope="row">Jun 1, 2023</th> <td> <a class="news-title" href="/news/announcement_2/">Multi-modal Speech Emotion Recognition: Improving Accuracy through Fusion of VGGish and BERT Features with Multi-head Attention</a> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/eai_iniscom/3m-ser-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/eai_iniscom/3m-ser-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/eai_iniscom/3m-ser-1400.webp"></source> <img src="/assets/img/eai_iniscom/3m-ser.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="eai_iniscom/3m-ser.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Springer:conf/EAI-INISCOM/3M-SER" class="col-sm-8"> <div class="title">Multi-modal Speech Emotion Recognition: Improving Accuracy Through Fusion of VGGish and BERT Features with Multi-head Attention</div> <div class="author"> <em>Phuong-Nam Tran</em>, Thuy-Duong Thi Vu, <a href="https://nhattruongpham.github.io/" rel="external nofollow noopener" target="_blank">Nhat Truong Pham</a>, <a href="https://scholar.google.com/citations?user=2UKP440AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a>, and <a href="https://scholar.google.com/citations?user=8_-FWD4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Anh-Khoa Tran</a> </div> <div class="periodical"> <em>In Industrial Networks and Intelligent Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-47359-3_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/namphuongtran9196/3m-ser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-47359-3_11" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Recent research has shown that multi-modal learning is a successful method for enhancing classification performance by mixing several forms of input, notably in speech-emotion recognition (SER) tasks. However, the difference between the modalities may affect SER performance. To overcome this problem, a novel approach for multi-modal SER called 3M-SER is proposed in this paper. The 3M-SER leverages multi-head attention to fuse information from multiple feature embeddings, including audio and text features. The 3M-SER approach is based on the SERVER approach but includes an additional fusion module that improves the integration of text and audio features, leading to improved classification performance. To further enhance the correlation between the modalities, a LayerNorm is applied to audio features prior to fusion. Our approach achieved an unweighted accuracy (UA) and weighted accuracy (WA) of 79.96% and 80.66%, respectively, on the IEMOCAP benchmark dataset. This indicates that the proposed approach is better than SERVER and recent methods with similar approaches. In addition, it highlights the effectiveness of incorporating an extra fusion module in multi-modal learning.</p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%61%6D%70%68%75%6F%6E%67%74%72%61%6E%39%31%39%36@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0009-0009-6551-9106" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=NKbwDD8AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/namphuongtran9196" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/namphuongtran9196" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://gitlab.com/namphuongtran9196" title="GitLab" rel="external nofollow noopener" target="_blank"><i class="fab fa-gitlab"></i></a> <a href="https://www.kaggle.com/tpnnam" title="Kaggle" rel="external nofollow noopener" target="_blank"><i class="fab fa-kaggle"></i></a> <a href="https://instagram.com/namphuongtran9196" title="Instagram" rel="external nofollow noopener" target="_blank"><i class="fab fa-instagram"></i></a> <a href="https://facebook.com/namphuongtran9196" title="Facebook" rel="external nofollow noopener" target="_blank"><i class="fab fa-facebook"></i></a> <a href="https://discord.com/users/840177865592537100" title="Discord" rel="external nofollow noopener" target="_blank"><i class="fab fa-discord"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> </div> </div> <div style="width: 150px; margin: 0 auto"> <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=xW7nMfAHDma4ZgSElvdBVQL-ntbmeGrv_H6wyuEbSpM&amp;cl=ffffff&amp;w=a"></script> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Phuong Nam Tran. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 19, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>